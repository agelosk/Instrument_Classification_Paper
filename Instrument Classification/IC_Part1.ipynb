{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrument Classification - Part 1 : Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start our first trial by trying to recognise piano (pia), acoustic guitar (gac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import math\n",
    "from random import shuffle\n",
    "from collections import deque\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpia = './Instrument-Classification/IRMAS-TrainingData/pia/'\n",
    "dirgac = './Instrument-Classification/IRMAS-TrainingData/gac/'\n",
    "dirgel = './Instrument-Classification/IRMAS-TrainingData/gel/'\n",
    "dirbuz = './Instrument-Classification/IRMAS-TrainingData/buz/'\n",
    "dirvio = './Instrument-Classification/IRMAS-TrainingData/vio/'\n",
    "dirvoi = './Instrument-Classification/IRMAS-TrainingData/voi/'\n",
    "dirpia_gac = './Instrument-Classification/IRMAS-TrainingData/pia-gac/'\n",
    "dirpia_gel = './Instrument-Classification/IRMAS-TrainingData/pia-gel/'\n",
    "dirpia_buz = './Instrument-Classification/IRMAS-TrainingData/pia-buz/'\n",
    "dirpia_vio = './Instrument-Classification/IRMAS-TrainingData/pia-vio/'\n",
    "dirpia_voi = './Instrument-Classification/IRMAS-TrainingData/pia-voi/'\n",
    "dirgac_gel = './Instrument-Classification/IRMAS-TrainingData/gac-gel/'\n",
    "dirgac_buz = './Instrument-Classification/IRMAS-TrainingData/gac-buz/'\n",
    "dirgac_vio = './Instrument-Classification/IRMAS-TrainingData/gac-vio/'\n",
    "dirgac_voi = './Instrument-Classification/IRMAS-TrainingData/gac-voi/'\n",
    "dirgel_buz = './Instrument-Classification/IRMAS-TrainingData/gel-buz/'\n",
    "dirgel_vio = './Instrument-Classification/IRMAS-TrainingData/gel-vio/'\n",
    "dirgel_voi = './Instrument-Classification/IRMAS-TrainingData/gel-voi/'\n",
    "dirbuz_vio = './Instrument-Classification/IRMAS-TrainingData/buz-vio/'\n",
    "dirbuz_voi = './Instrument-Classification/IRMAS-TrainingData/buz-voi/'\n",
    "dirvio_voi = './Instrument-Classification/IRMAS-TrainingData/vio-voi/'\n",
    "\n",
    "dirnot_pia = './Instrument-Classification/IRMAS-TrainingData/not-piano/'\n",
    "\n",
    "#instr = ['pia','gac','gel','buz','vio','voi']\n",
    "instr = ['pia','gac']\n",
    "\n",
    "#dir = [dirpia,     dirgac,     dirgel,     dirbuz,     dirvio,    dirvoi,\n",
    "#       dirpia_gac, dirpia_gel, dirpia_buz, dirpia_vio, dirpia_voi,\n",
    "#       dirgac_gel, dirgac_buz, dirgac_vio, dirgac_voi,\n",
    "#       dirgel_buz, dirgel_vio, dirgel_voi,\n",
    "#       dirbuz_vio, dirbuz_voi,\n",
    "#       dirvio_voi]\n",
    "\n",
    "dir_array = [dirpia,dirgac,dirpia_gac]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(dir_array):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    check = 0\n",
    "    for dir in dir_array:\n",
    "        for f in os.listdir(dir):\n",
    "            try:\n",
    "                label = dir.split('/')\n",
    "            \n",
    "                # downsampled to 22050Hz and downmixed to mono\n",
    "                wav,sr = librosa.load(dir+f,mono=True,sr=22050)\n",
    "        \n",
    "                # normalized by the root mean square energy\n",
    "                wav = wav / np.sqrt(np.mean(wav**2))\n",
    "        \n",
    "                # transformed into mel-spectrograms with given traits\n",
    "                #mel = librosa.feature.melspectrogram(wav,n_mels=96,fmax=11025,n_fft=1024,hop_length=256,power=1)\n",
    "                mel = librosa.core.cqt(wav,n_bins=96,hop_length=256)\n",
    "            \n",
    "                # decibel scaling\n",
    "                mel = librosa.core.amplitude_to_db(np.abs(mel))\n",
    "                \n",
    "                #just for checking\n",
    "                if (check%500==0): \n",
    "                    print(check,\" chuncks have been made!\")\n",
    "                check+=1\n",
    "        \n",
    "                y_list.append(label[-2])\n",
    "                x_list.append(mel)\n",
    "            sexcept:\n",
    "                print(\"Empty Track: \",f)\n",
    "    return (x_list,y_list)\n",
    "\n",
    "def to_categorical(list):\n",
    "    list_final = []\n",
    "    for label in list:\n",
    "        list_final.append(label.split('-'))\n",
    "    temp_list = [[0]*len(instr)]*(len(list_final))\n",
    "    for i in range(len(list_final)):\n",
    "        x = [0]*len(instr)\n",
    "        x.insert(0,1)\n",
    "        x.pop()\n",
    "        for ins in instr:\n",
    "            if (ins in list_final[i]): \n",
    "                temp_list[i] = [sum(x) for x in zip(temp_list[i],x)]\n",
    "            x.insert(0,x.pop())\n",
    "    return temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  chuncks have been made!\n",
      "500  chuncks have been made!\n",
      "1000  chuncks have been made!\n",
      "1500  chuncks have been made!\n",
      "2000  chuncks have been made!\n",
      "2500  chuncks have been made!\n",
      "3000  chuncks have been made!\n",
      "3500  chuncks have been made!\n",
      "4000  chuncks have been made!\n",
      "4500  chuncks have been made!\n",
      "5000  chuncks have been made!\n",
      "5500  chuncks have been made!\n",
      "6000  chuncks have been made!\n",
      "6500  chuncks have been made!\n",
      "7000  chuncks have been made!\n",
      "7500  chuncks have been made!\n",
      "8000  chuncks have been made!\n",
      "8500  chuncks have been made!\n",
      "9000  chuncks have been made!\n",
      "9500  chuncks have been made!\n",
      "10000  chuncks have been made!\n",
      "10500  chuncks have been made!\n",
      "11000  chuncks have been made!\n",
      "11500  chuncks have been made!\n",
      "12000  chuncks have been made!\n",
      "12500  chuncks have been made!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AgelosK\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Track:  3_1731_a_n.wav\n",
      "13000  chuncks have been made!\n",
      "Empty Track:  3_2026_a_n.wav\n",
      "Empty Track:  3_2027_a_n.wav\n",
      "13500  chuncks have been made!\n",
      "Empty Track:  3_2353_a_n.wav\n",
      "14000  chuncks have been made!\n",
      "Empty Track:  3_2701_a_n.wav\n",
      "14500  chuncks have been made!\n",
      "15000  chuncks have been made!\n",
      "15500  chuncks have been made!\n",
      "16000  chuncks have been made!\n",
      "16500  chuncks have been made!\n",
      "17000  chuncks have been made!\n",
      "17500  chuncks have been made!\n",
      "18000  chuncks have been made!\n",
      "18500  chuncks have been made!\n",
      "19000  chuncks have been made!\n",
      "19500  chuncks have been made!\n",
      "20000  chuncks have been made!\n",
      "20500  chuncks have been made!\n",
      "21000  chuncks have been made!\n",
      "21500  chuncks have been made!\n",
      "22000  chuncks have been made!\n",
      "22500  chuncks have been made!\n",
      "23000  chuncks have been made!\n",
      "23500  chuncks have been made!\n",
      "24000  chuncks have been made!\n",
      "24500  chuncks have been made!\n",
      "25000  chuncks have been made!\n",
      "25500  chuncks have been made!\n",
      "26000  chuncks have been made!\n",
      "26500  chuncks have been made!\n",
      "27000  chuncks have been made!\n",
      "27500  chuncks have been made!\n",
      "28000  chuncks have been made!\n",
      "28500  chuncks have been made!\n",
      "29000  chuncks have been made!\n",
      "29500  chuncks have been made!\n",
      "30000  chuncks have been made!\n",
      "30500  chuncks have been made!\n",
      "31000  chuncks have been made!\n",
      "31500  chuncks have been made!\n",
      "32000  chuncks have been made!\n",
      "32500  chuncks have been made!\n",
      "33000  chuncks have been made!\n",
      "33500  chuncks have been made!\n",
      "34000  chuncks have been made!\n",
      "34500  chuncks have been made!\n",
      "35000  chuncks have been made!\n",
      "35500  chuncks have been made!\n",
      "36000  chuncks have been made!\n",
      "36500  chuncks have been made!\n",
      "37000  chuncks have been made!\n",
      "37500  chuncks have been made!\n",
      "38000  chuncks have been made!\n",
      "38500  chuncks have been made!\n",
      "39000  chuncks have been made!\n",
      "39500  chuncks have been made!\n",
      "40000  chuncks have been made!\n",
      "40500  chuncks have been made!\n",
      "41000  chuncks have been made!\n",
      "41500  chuncks have been made!\n",
      "42000  chuncks have been made!\n",
      "42500  chuncks have been made!\n",
      "43000  chuncks have been made!\n",
      "43500  chuncks have been made!\n",
      "44000  chuncks have been made!\n",
      "44500  chuncks have been made!\n",
      "45000  chuncks have been made!\n",
      "45500  chuncks have been made!\n",
      "46000  chuncks have been made!\n",
      "46500  chuncks have been made!\n",
      "Train Size: (42008, 96, 87, 1)\n",
      "Test  Size: (4668, 96, 87, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_list,y_list) = pre_processing(dir_array)\n",
    "\n",
    "x_list = np.expand_dims(np.array(x_list),-1)\n",
    "y_list = np.array(to_categorical(y_list))\n",
    "\n",
    "#shuffling sets\n",
    "id = np.random.permutation(len(x_list))\n",
    "x_list,y_list = x_list[id], y_list[id]\n",
    "\n",
    "#splitting to train and test 90/10\n",
    "split_index = math.floor(len(x_list)*0.90)\n",
    "x_train = x_list[:split_index]\n",
    "y_train = y_list[:split_index]\n",
    "x_test  = x_list[split_index:]\n",
    "y_test  = y_list[split_index:]\n",
    "\n",
    "print(\"Train Size:\", x_train.shape)\n",
    "print(\"Test  Size:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_trainPGm_CQT_big.npy',x_train)\n",
    "np.save('x_testPGm_CQT_big.npy' ,x_test)\n",
    "np.save('y_trainPGm_CQT_big.npy',y_train)\n",
    "np.save('y_testPGm_CQT_big.npy' ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
