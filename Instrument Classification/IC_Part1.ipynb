{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrument Classification - Part 1 : Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa, os, math\n",
    "from random import shuffle\n",
    "from collections import deque\n",
    "\n",
    "dirpia = 'D:/IC_Data/Dataset/1.pia/'\n",
    "dirgac = 'D:/IC_Data/Dataset/2.gac/'\n",
    "dirgel = 'D:/IC_Data/Dataset/3.gel/'\n",
    "dirvio = 'D:/IC_Data/Dataset/4.vio/'\n",
    "dircel = 'D:/IC_Data/Dataset/5.cel/'\n",
    "dirsax = 'D:/IC_Data/Dataset/6.sax/'\n",
    "dirtru = 'D:/IC_Data/Dataset/7.tru/'\n",
    "dircla = 'D:/IC_Data/Dataset/8.cla/'\n",
    "dirvoi = 'D:/IC_Data/Dataset/9.voi/'\n",
    "\n",
    "dirpiagac = 'D:/IC_Data/Dataset/pia-gac/'\n",
    "dirpiagel = 'D:/IC_Data/Dataset/pia-gel/'\n",
    "dirpiavio = 'D:/IC_Data/Dataset/pia-vio/'\n",
    "dirpiacel = 'D:/IC_Data/Dataset/pia-cel/'\n",
    "dirpiasax = 'D:/IC_Data/Dataset/pia-sax/'\n",
    "dirpiatru = 'D:/IC_Data/Dataset/pia-tru/'\n",
    "dirpiacla = 'D:/IC_Data/Dataset/pia-cla/'\n",
    "dirpiavoi = 'D:/IC_Data/Dataset/pia-voi/'\n",
    "dirgacgel = 'D:/IC_Data/Dataset/gac-gel/'\n",
    "dirgacvio = 'D:/IC_Data/Dataset/gac-vio/'\n",
    "dirgaccel = 'D:/IC_Data/Dataset/gac-cel/'\n",
    "dirgacsax = 'D:/IC_Data/Dataset/gac-sax/'\n",
    "dirgactru = 'D:/IC_Data/Dataset/gac-tru/'\n",
    "dirgaccla = 'D:/IC_Data/Dataset/gac-cla/'\n",
    "dirgacvoi = 'D:/IC_Data/Dataset/gac-voi/'\n",
    "dirgelvio = 'D:/IC_Data/Dataset/gel-vio/'\n",
    "dirgelcel = 'D:/IC_Data/Dataset/gel-cel/'\n",
    "dirgelsax = 'D:/IC_Data/Dataset/gel-sax/'\n",
    "dirgeltru = 'D:/IC_Data/Dataset/gel-tru/'\n",
    "dirgelcla = 'D:/IC_Data/Dataset/gel-cla/'\n",
    "dirgelvoi = 'D:/IC_Data/Dataset/gel-voi/'\n",
    "dirviocel = 'D:/IC_Data/Dataset/vio-cel/'\n",
    "dirviosax = 'D:/IC_Data/Dataset/vio-sax/'\n",
    "dirviotru = 'D:/IC_Data/Dataset/vio-tru/'\n",
    "dirviocla = 'D:/IC_Data/Dataset/vio-cla/'\n",
    "dirviovoi = 'D:/IC_Data/Dataset/vio-voi/'\n",
    "dircelsax = 'D:/IC_Data/Dataset/cel-sax/'\n",
    "dirceltru = 'D:/IC_Data/Dataset/cel-tru/'\n",
    "dircelcla = 'D:/IC_Data/Dataset/cel-cla/'\n",
    "dircelvoi = 'D:/IC_Data/Dataset/cel-voi/'\n",
    "dirsaxtru = 'D:/IC_Data/Dataset/sax-tru/'\n",
    "dirsaxcla = 'D:/IC_Data/Dataset/sax-cla/'\n",
    "dirsaxvoi = 'D:/IC_Data/Dataset/sax-voi/'\n",
    "dirtrucla = 'D:/IC_Data/Dataset/tru-cla/'\n",
    "dirtruvoi = 'D:/IC_Data/Dataset/tru-voi/'\n",
    "dirclavoi = 'D:/IC_Data/Dataset/cla-voi/'\n",
    "\n",
    "dir_array = [dirpia,dirgac,dirgel,dirvio,dircel,dirsax,dirtru,dircla,dirvoi,dirpiagac,dirpiagel,dirpiavio,\n",
    "             dirpiacel,dirpiasax,dirpiatru,dirpiacla,dirpiavoi,dirgacgel,dirgacvio,dirgaccel,dirgacsax,\n",
    "             dirgactru,dirgaccla,dirgacvoi,dirgelvio,dirgelcel,dirgelsax,dirgeltru,dirgelcla,dirgelvoi,\n",
    "             dirviocel,dirviosax,dirviotru,dirviocla,dirviovoi,dircelsax,dirceltru,dircelcla,dircelvoi,\n",
    "             dirsaxtru,dirsaxcla,dirsaxvoi,dirtrucla,dirtruvoi,dirclavoi]\n",
    "\n",
    "inst = ['pia','gac','gel','vio','cel','sax','tru','cla','voi','pia-gac','pia-gel','pia-vio',\n",
    "        'pia-cel','pia-sax','pia-tru','pia-cla','pia-voi','gac-gel','gac-vio','gac-cel','gac-sax',\n",
    "        'gac-tru','gac-cla','gac-voi','gel-vio','gel-cel','gel-sax','gel-tru','gel-cla','gel-voi',\n",
    "        'vio-cel','vio-sax','vio-tru','vio-cla','vio-voi','cel-sax','cel-tru','cel-cla','cel-voi',\n",
    "        'sax-tru','sax-cla','sax-voi','tru-cla','tru-voi','cla-voi']\n",
    "\n",
    "def pre_processing(dir_array):\n",
    "    x_list = []\n",
    "    check = 0\n",
    "    for dir in dir_array:\n",
    "        for f in os.listdir(dir):\n",
    "            try:\n",
    "                label = dir.split('/')\n",
    "                # downsampled to 22050Hz and downmixed to mono\n",
    "                wav,sr = librosa.load(dir+f,mono=True,sr=22050)\n",
    "                # normalized by the root mean square energy\n",
    "                wav = wav / np.sqrt(np.mean(wav**2))\n",
    "                # transformed into spectrograms\n",
    "                cqt = librosa.core.cqt(wav,n_bins=96,bins_per_octave=12,hop_length=256)\n",
    "                # decibel scaling\n",
    "                cqt = librosa.core.amplitude_to_db(np.abs(cqt))\n",
    "                #just for checking\n",
    "                if (check%500==0): print(check,\"chunks have been made!\")\n",
    "                check += 1\n",
    "                x_list.append(cqt)\n",
    "            except:\n",
    "                print(\"Empty Track: \",f)\n",
    "                os.remove(dir+f)\n",
    "    return x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 chunks have been made!\n",
      "500 chunks have been made!\n",
      "1000 chunks have been made!\n",
      "1500 chunks have been made!\n",
      "2000 chunks have been made!\n",
      "2500 chunks have been made!\n",
      "3000 chunks have been made!\n",
      "3500 chunks have been made!\n",
      "4000 chunks have been made!\n",
      "4500 chunks have been made!\n",
      "Train Size: (4500, 96, 87, 1)\n",
      "Test  Size: (500, 96, 87, 1)\n",
      "0 chunks have been made!\n",
      "500 chunks have been made!\n",
      "1000 chunks have been made!\n",
      "1500 chunks have been made!\n",
      "2000 chunks have been made!\n",
      "2500 chunks have been made!\n",
      "3000 chunks have been made!\n",
      "3500 chunks have been made!\n",
      "4000 chunks have been made!\n",
      "4500 chunks have been made!\n",
      "Train Size: (4500, 96, 87, 1)\n",
      "Test  Size: (500, 96, 87, 1)\n",
      "0 chunks have been made!\n",
      "500 chunks have been made!\n",
      "1000 chunks have been made!\n",
      "1500 chunks have been made!\n",
      "2000 chunks have been made!\n",
      "2500 chunks have been made!\n",
      "3000 chunks have been made!\n",
      "3500 chunks have been made!\n",
      "4000 chunks have been made!\n",
      "4500 chunks have been made!\n",
      "Train Size: (4500, 96, 87, 1)\n",
      "Test  Size: (500, 96, 87, 1)\n",
      "0 chunks have been made!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kavra\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Track:  1_1126_vi.wav\n",
      "500 chunks have been made!\n",
      "1000 chunks have been made!\n",
      "1500 chunks have been made!\n",
      "2000 chunks have been made!\n",
      "2500 chunks have been made!\n",
      "3000 chunks have been made!\n",
      "3500 chunks have been made!\n",
      "4000 chunks have been made!\n",
      "4500 chunks have been made!\n",
      "Train Size: (4499, 96, 87, 1)\n",
      "Test  Size: (500, 96, 87, 1)\n",
      "0 chunks have been made!\n",
      "500 chunks have been made!\n",
      "1000 chunks have been made!\n",
      "1500 chunks have been made!\n",
      "2000 chunks have been made!\n",
      "2500 chunks have been made!\n",
      "3000 chunks have been made!\n",
      "3500 chunks have been made!\n",
      "4000 chunks have been made!\n",
      "4500 chunks have been made!\n",
      "Train Size: (4500, 96, 87, 1)\n",
      "Test  Size: (500, 96, 87, 1)\n",
      "0 chunks have been made!\n",
      "500 chunks have been made!\n",
      "1000 chunks have been made!\n",
      "1500 chunks have been made!\n",
      "2000 chunks have been made!\n",
      "2500 chunks have been made!\n",
      "3000 chunks have been made!\n",
      "3500 chunks have been made!\n",
      "4000 chunks have been made!\n",
      "4500 chunks have been made!\n",
      "Train Size: (4500, 96, 87, 1)\n",
      "Test  Size: (500, 96, 87, 1)\n",
      "0 chunks have been made!\n",
      "500 chunks have been made!\n",
      "1000 chunks have been made!\n",
      "1500 chunks have been made!\n",
      "2000 chunks have been made!\n",
      "2500 chunks have been made!\n",
      "3000 chunks have been made!\n",
      "3500 chunks have been made!\n",
      "4000 chunks have been made!\n",
      "4500 chunks have been made!\n",
      "Train Size: (4500, 96, 87, 1)\n",
      "Test  Size: (500, 96, 87, 1)\n",
      "0 chunks have been made!\n",
      "500 chunks have been made!\n",
      "1000 chunks have been made!\n",
      "1500 chunks have been made!\n",
      "2000 chunks have been made!\n",
      "2500 chunks have been made!\n",
      "3000 chunks have been made!\n",
      "3500 chunks have been made!\n",
      "4000 chunks have been made!\n",
      "4500 chunks have been made!\n",
      "Train Size: (4500, 96, 87, 1)\n",
      "Test  Size: (500, 96, 87, 1)\n",
      "0 chunks have been made!\n",
      "500 chunks have been made!\n",
      "1000 chunks have been made!\n",
      "1500 chunks have been made!\n",
      "2000 chunks have been made!\n",
      "2500 chunks have been made!\n",
      "3000 chunks have been made!\n",
      "3500 chunks have been made!\n",
      "4000 chunks have been made!\n",
      "4500 chunks have been made!\n",
      "Train Size: (4500, 96, 87, 1)\n",
      "Test  Size: (500, 96, 87, 1)\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for dir in dir_array:\n",
    "    x_list = pre_processing([dir])\n",
    "    x_list = np.expand_dims(np.array(x_list),-1)\n",
    "    # shuffling\n",
    "    id = np.random.permutation(len(x_list))\n",
    "    x_list = x_list[id]\n",
    "    # splitting to train and test 90/10\n",
    "    split_index = math.floor(len(x_list)*0.90)\n",
    "    x_train = x_list[:split_index]\n",
    "    x_test  = x_list[split_index:]\n",
    "\n",
    "    print(\"Train Size:\", x_train.shape)\n",
    "    print(\"Test  Size:\", x_test.shape)\n",
    "    np.save('x_train_'+inst[i]+'.npy',x_train)\n",
    "    np.save('x_test_'+inst[i]+'.npy' ,x_test)\n",
    "    i=i+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
