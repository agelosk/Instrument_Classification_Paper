{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrument Classification - Part 1 : Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start our first trial by trying to recognise piano (pia), acoustic guitar (gac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import math\n",
    "from random import shuffle\n",
    "from collections import deque\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpia = './Instrument-Classification/IRMAS-TrainingData/pia/'\n",
    "dirgac = './Instrument-Classification/IRMAS-TrainingData/gac/'\n",
    "#dirsax = './Instrument-Classification/IRMAS-TrainingData/sax/'\n",
    "#dirvoi = './Instrument-Classification/IRMAS-TrainingData/voi/'\n",
    "\n",
    "#instr = ['pia','gac','sax','voi']\n",
    "#dir = [dirpia,dirgac,dirsax,dirvoi]\n",
    "\n",
    "instr = ['pia','gac']\n",
    "dir = [dirpia,dirgac]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(dir_array):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    list = []\n",
    "    for dir in dir_array:\n",
    "        for f in os.listdir(dir):\n",
    "            list.append(dir+f)\n",
    "    check = 0\n",
    "    for f in list:\n",
    "        label = f.split('/')\n",
    "        # downsampled to 22050Hz and downmixed to mono\n",
    "        wav,sr = librosa.load(f,mono=True,sr=22050)\n",
    "        # normalized by the root mean square energy\n",
    "        wav = wav / np.sqrt(np.mean(wav**2))\n",
    "        # chunked to 1sec long snippets\n",
    "        chunks = make_chunks(wav,sr)\n",
    "        for wav in chunks:\n",
    "            # transformed into mel-spectrograms with given traits\n",
    "            mel = librosa.feature.melspectrogram(wav,n_mels=96,fmax=11025,n_fft=1024,hop_length=256,power=1)\n",
    "            # decibel scaling\n",
    "            mel = librosa.core.amplitude_to_db(mel)\n",
    "            # saved to train and test arrays\n",
    "                \n",
    "            #just for checking\n",
    "            if (check == 500): \n",
    "                print(\"Another 500 chuncks have been made!\")\n",
    "                check=0\n",
    "            else: \n",
    "                check+=1\n",
    "            y_list.append(label[-2])\n",
    "            x_list.append(mel)\n",
    "    return (x_list,y_list)\n",
    "\n",
    "def to_categorical(list):\n",
    "    temp_list = [[0]*len(instr)]*(len(list))\n",
    "    for i in range(len(list)):\n",
    "        x = [0]*len(instr)\n",
    "        x.insert(0,1)\n",
    "        x.pop()\n",
    "        for ins in instr:\n",
    "            if (ins in list[i]): \n",
    "                temp_list[i] = [sum(x) for x in zip(temp_list[i],x)]\n",
    "            x.insert(0,x.pop())\n",
    "    return temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Another 500 chuncks have been made!\n",
      "Train Size: (12401, 96, 87, 1)\n",
      "Test  Size: (1378, 96, 87, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_list,y_list) = pre_processing(dir)\n",
    "\n",
    "x_list = np.expand_dims(np.array(x_list),-1)\n",
    "y_list = np.array(to_categorical(y_list))\n",
    "\n",
    "#shuffling sets\n",
    "id = np.random.permutation(len(x_list))\n",
    "x_list,y_list = x_list[id], y_list[id]\n",
    "\n",
    "#splitting to train and test 90/10\n",
    "split_index = math.floor(len(x_list)*0.90)\n",
    "x_train = x_list[:split_index]\n",
    "y_train = y_list[:split_index]\n",
    "x_test  = x_list[split_index:]\n",
    "y_test  = y_list[split_index:]\n",
    "\n",
    "print(\"Train Size:\", x_train.shape)\n",
    "print(\"Test  Size:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_trainB.npy',x_train)\n",
    "np.save('x_testB.npy' ,x_test)\n",
    "np.save('y_trainB.npy',y_train)\n",
    "np.save('y_testB.npy' ,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
